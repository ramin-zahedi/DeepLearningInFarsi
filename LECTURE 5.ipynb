{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2ed942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f11a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()# splits the string into a list of strings, using line breaks as the separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68317d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2294132d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "\n",
    "stoi['.'] = 0\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "632912b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = {value:key for key, value in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "019dc82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". e\n",
      "e m\n",
      "m m\n",
      "m a\n",
      "a .\n"
     ]
    }
   ],
   "source": [
    "# create the training set of bigrams (x,y)\n",
    "xs, ys = [], []                        ###\n",
    "\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]                ###\n",
    "        ix2 = stoi[ch2]                ###\n",
    "        print(ch1, ch2)\n",
    "        xs.append(ix1)                 ###\n",
    "        ys.append(ix2)                 ###\n",
    "    \n",
    "xs = torch.tensor(xs)                  ###\n",
    "ys = torch.tensor(ys)                  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e4fd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e3fda3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bdb07e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc = torch.nn.functional.one_hot(xs, num_classes=27).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb13e23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3377e819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f1e4ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2097])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn((27, 1))\n",
    "xenc[0] @ W # one neuron output (1, 27) @ (27, 1) -> (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69858e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2097],\n",
       "        [ 0.5425],\n",
       "        [-0.8667],\n",
       "        [-0.8667],\n",
       "        [ 1.2896]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc @ W #Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce735f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5113, -1.2889,  0.6511,  1.4577, -1.8795, -1.8569, -0.6685, -0.3807,\n",
       "          0.1299, -0.5953,  0.3240, -0.6966,  0.1884,  1.3102, -0.8770, -1.6961,\n",
       "          0.0131, -2.0565,  0.7665,  0.7568,  0.0504, -0.5717, -0.0621,  1.3506,\n",
       "          0.2363, -0.2872, -0.9544],\n",
       "        [-0.4569, -1.6088,  0.2555,  0.2293,  0.9758, -0.0554, -1.0687, -0.3408,\n",
       "          0.3882,  1.2667, -1.9132,  1.0240,  0.0253, -0.5618, -0.1042,  0.0165,\n",
       "         -1.6488,  0.9745,  0.7305, -1.1469, -0.5620,  0.4836,  0.0942,  0.8132,\n",
       "          0.5246, -0.1325,  0.5245],\n",
       "        [ 1.1489, -0.5758,  1.1291,  0.8534,  0.1623, -0.6800, -0.3093,  1.9961,\n",
       "          0.2742,  0.0604,  0.7210, -0.7238,  0.5377,  1.1540,  0.9461, -0.1802,\n",
       "         -0.0296,  0.1697, -0.7552,  0.1991, -0.2870, -0.6825,  0.6623, -0.5634,\n",
       "          0.6878,  0.7256, -0.9141],\n",
       "        [ 1.1489, -0.5758,  1.1291,  0.8534,  0.1623, -0.6800, -0.3093,  1.9961,\n",
       "          0.2742,  0.0604,  0.7210, -0.7238,  0.5377,  1.1540,  0.9461, -0.1802,\n",
       "         -0.0296,  0.1697, -0.7552,  0.1991, -0.2870, -0.6825,  0.6623, -0.5634,\n",
       "          0.6878,  0.7256, -0.9141],\n",
       "        [ 0.1538, -0.4423,  0.2571, -0.5441, -0.0040, -0.1883, -1.3892,  0.6946,\n",
       "          1.5629, -0.2434, -0.3497,  0.4397,  0.7812, -0.1245,  0.2863, -0.0631,\n",
       "         -0.1552,  0.8919,  2.0051, -0.5913,  0.5656, -1.1934, -0.6167,  0.6303,\n",
       "          2.0352, -1.6818, -0.4669]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn((27, 27), requires_grad=True) # 729 parameters\n",
    "xenc @ W # (5, 27) @ (27, 27) -> (5, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de0b01ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0505, 0.0084, 0.0581, 0.1302, 0.0046, 0.0047, 0.0155, 0.0207, 0.0345,\n",
       "         0.0167, 0.0419, 0.0151, 0.0366, 0.1124, 0.0126, 0.0056, 0.0307, 0.0039,\n",
       "         0.0652, 0.0646, 0.0319, 0.0171, 0.0285, 0.1170, 0.0384, 0.0227, 0.0117],\n",
       "        [0.0183, 0.0058, 0.0374, 0.0364, 0.0768, 0.0274, 0.0099, 0.0206, 0.0427,\n",
       "         0.1027, 0.0043, 0.0806, 0.0297, 0.0165, 0.0261, 0.0294, 0.0056, 0.0767,\n",
       "         0.0601, 0.0092, 0.0165, 0.0470, 0.0318, 0.0653, 0.0489, 0.0254, 0.0489],\n",
       "        [0.0713, 0.0127, 0.0700, 0.0531, 0.0266, 0.0115, 0.0166, 0.1665, 0.0298,\n",
       "         0.0240, 0.0465, 0.0110, 0.0387, 0.0717, 0.0583, 0.0189, 0.0220, 0.0268,\n",
       "         0.0106, 0.0276, 0.0170, 0.0114, 0.0439, 0.0129, 0.0450, 0.0467, 0.0091],\n",
       "        [0.0713, 0.0127, 0.0700, 0.0531, 0.0266, 0.0115, 0.0166, 0.1665, 0.0298,\n",
       "         0.0240, 0.0465, 0.0110, 0.0387, 0.0717, 0.0583, 0.0189, 0.0220, 0.0268,\n",
       "         0.0106, 0.0276, 0.0170, 0.0114, 0.0439, 0.0129, 0.0450, 0.0467, 0.0091],\n",
       "        [0.0258, 0.0142, 0.0287, 0.0129, 0.0221, 0.0184, 0.0055, 0.0444, 0.1057,\n",
       "         0.0174, 0.0156, 0.0344, 0.0484, 0.0196, 0.0295, 0.0208, 0.0190, 0.0541,\n",
       "         0.1645, 0.0123, 0.0390, 0.0067, 0.0120, 0.0416, 0.1696, 0.0041, 0.0139]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = xenc @ W # log-counts (5, 27) @ (27, 27) -> (5, 27)\n",
    "counts = logits.exp() # similar N (5, 27)\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character (5, 27)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "610aab70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ecc109d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0505, 0.0084, 0.0581, 0.1302, 0.0046, 0.0047, 0.0155, 0.0207, 0.0345,\n",
       "        0.0167, 0.0419, 0.0151, 0.0366, 0.1124, 0.0126, 0.0056, 0.0307, 0.0039,\n",
       "        0.0652, 0.0646, 0.0319, 0.0171, 0.0285, 0.1170, 0.0384, 0.0227, 0.0117],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88c500ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfa3b1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45879d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram example: .e (indexes 0,5)\n",
      "input:  0\n",
      "output:\n",
      " tensor([0.0505, 0.0084, 0.0581, 0.1302, 0.0046, 0.0047, 0.0155, 0.0207, 0.0345,\n",
      "        0.0167, 0.0419, 0.0151, 0.0366, 0.1124, 0.0126, 0.0056, 0.0307, 0.0039,\n",
      "        0.0652, 0.0646, 0.0319, 0.0171, 0.0285, 0.1170, 0.0384, 0.0227, 0.0117],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "label:  5\n",
      "probability assigned by the net to the the correct character:  0.0047335815615952015\n",
      "log likelihood: -5.3530731201171875\n",
      "negative log likelihood: 5.3530731201171875\n"
     ]
    }
   ],
   "source": [
    "x = xs[0].item() # input character index\n",
    "y = ys[0].item() # label character index\n",
    "print(f'bigram example: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
    "print('input: ', x)\n",
    "print('output:\\n', probs[0])\n",
    "print('label: ', y)\n",
    "print('probability assigned by the net to the the correct character: ', probs[0, y].item())\n",
    "print('log likelihood:', torch.log(probs[0, y]).item())\n",
    "print('negative log likelihood:', -torch.log(probs[0, y]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d3d185c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram example: ma (indexes 13,1)\n",
      "input:  13\n",
      "output:\n",
      " tensor([0.0713, 0.0127, 0.0700, 0.0531, 0.0266, 0.0115, 0.0166, 0.1665, 0.0298,\n",
      "        0.0240, 0.0465, 0.0110, 0.0387, 0.0717, 0.0583, 0.0189, 0.0220, 0.0268,\n",
      "        0.0106, 0.0276, 0.0170, 0.0114, 0.0439, 0.0129, 0.0450, 0.0467, 0.0091],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "label:  1\n",
      "probability assigned by the net to the the correct character:  0.012716551311314106\n",
      "log likelihood: -4.364850997924805\n",
      "negative log likelihood: 4.364850997924805\n"
     ]
    }
   ],
   "source": [
    "x = xs[3].item() # input character index\n",
    "y = ys[3].item() # label character index\n",
    "print(f'bigram example: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
    "print('input: ', x)\n",
    "print('output:\\n', probs[3])\n",
    "print('label: ', y)\n",
    "print('probability assigned by the net to the the correct character: ', probs[3, y].item())\n",
    "print('log likelihood:', torch.log(probs[3, y]).item())\n",
    "print('negative log likelihood:', -torch.log(probs[3, y]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0419a60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "bigram example: .e (indexes 0,5)\n",
      "input:  0\n",
      "output:\n",
      " tensor([0.0505, 0.0084, 0.0581, 0.1302, 0.0046, 0.0047, 0.0155, 0.0207, 0.0345,\n",
      "        0.0167, 0.0419, 0.0151, 0.0366, 0.1124, 0.0126, 0.0056, 0.0307, 0.0039,\n",
      "        0.0652, 0.0646, 0.0319, 0.0171, 0.0285, 0.1170, 0.0384, 0.0227, 0.0117],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "label:  5\n",
      "probability assigned by the net to the the correct character:  0.0047335815615952015\n",
      "log likelihood: -5.3530731201171875\n",
      "negative log likelihood: 5.3530731201171875\n",
      "--------\n",
      "bigram example: em (indexes 5,13)\n",
      "input:  5\n",
      "output:\n",
      " tensor([0.0183, 0.0058, 0.0374, 0.0364, 0.0768, 0.0274, 0.0099, 0.0206, 0.0427,\n",
      "        0.1027, 0.0043, 0.0806, 0.0297, 0.0165, 0.0261, 0.0294, 0.0056, 0.0767,\n",
      "        0.0601, 0.0092, 0.0165, 0.0470, 0.0318, 0.0653, 0.0489, 0.0254, 0.0489],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "label:  13\n",
      "probability assigned by the net to the the correct character:  0.016507331281900406\n",
      "log likelihood: -4.103950500488281\n",
      "negative log likelihood: 4.103950500488281\n",
      "--------\n",
      "bigram example: mm (indexes 13,13)\n",
      "input:  13\n",
      "output:\n",
      " tensor([0.0713, 0.0127, 0.0700, 0.0531, 0.0266, 0.0115, 0.0166, 0.1665, 0.0298,\n",
      "        0.0240, 0.0465, 0.0110, 0.0387, 0.0717, 0.0583, 0.0189, 0.0220, 0.0268,\n",
      "        0.0106, 0.0276, 0.0170, 0.0114, 0.0439, 0.0129, 0.0450, 0.0467, 0.0091],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "label:  13\n",
      "probability assigned by the net to the the correct character:  0.07171885669231415\n",
      "log likelihood: -2.6350016593933105\n",
      "negative log likelihood: 2.6350016593933105\n",
      "--------\n",
      "bigram example: ma (indexes 13,1)\n",
      "input:  13\n",
      "output:\n",
      " tensor([0.0713, 0.0127, 0.0700, 0.0531, 0.0266, 0.0115, 0.0166, 0.1665, 0.0298,\n",
      "        0.0240, 0.0465, 0.0110, 0.0387, 0.0717, 0.0583, 0.0189, 0.0220, 0.0268,\n",
      "        0.0106, 0.0276, 0.0170, 0.0114, 0.0439, 0.0129, 0.0450, 0.0467, 0.0091],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "label:  1\n",
      "probability assigned by the net to the the correct character:  0.012716551311314106\n",
      "log likelihood: -4.364850997924805\n",
      "negative log likelihood: 4.364850997924805\n",
      "--------\n",
      "bigram example: a. (indexes 1,0)\n",
      "input:  1\n",
      "output:\n",
      " tensor([0.0258, 0.0142, 0.0287, 0.0129, 0.0221, 0.0184, 0.0055, 0.0444, 0.1057,\n",
      "        0.0174, 0.0156, 0.0344, 0.0484, 0.0196, 0.0295, 0.0208, 0.0190, 0.0541,\n",
      "        0.1645, 0.0123, 0.0390, 0.0067, 0.0120, 0.0416, 0.1696, 0.0041, 0.0139],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "label:  0\n",
      "probability assigned by the net to the the correct character:  0.0258389413356781\n",
      "log likelihood: -3.6558725833892822\n",
      "negative log likelihood: 3.6558725833892822\n",
      "=========\n",
      "average negative log likelihood, i.e. loss = 4.022549629211426\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)                                                       ###\n",
    "for i in range(5):    \n",
    "    x = xs[i].item() # input character index\n",
    "    y = ys[i].item() # label character index\n",
    "    print('--------')\n",
    "    print(f'bigram example: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
    "    print('input: ', x)\n",
    "    print('output:\\n', probs[i])\n",
    "    print('label: ', y)\n",
    "    print('probability assigned by the net to the the correct character: ', probs[i, y].item())\n",
    "    print('log likelihood:', torch.log(probs[i, y]).item())\n",
    "    print('negative log likelihood:', -torch.log(probs[i, y]).item())\n",
    "    nlls[i] = -torch.log(probs[i, y]).item()                               ###\n",
    "    \n",
    "print('=========')                                                         ###\n",
    "print('average negative log likelihood, i.e. loss =', nlls.mean().item())  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4e7e0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# create the training set of bigrams (x,y)\n",
    "xs, ys = [], []                       \n",
    "\n",
    "for w in words:                        ###\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]                \n",
    "        ix2 = stoi[ch2]                \n",
    "        #print(ch1, ch2)\n",
    "        xs.append(ix1)                 \n",
    "        ys.append(ix2)                 \n",
    "    \n",
    "xs = torch.tensor(xs)                  \n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "num = xs.nelement()                ###\n",
    "print('number of examples: ', num) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdaf548a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 27])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc = torch.nn.functional.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b538a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = xenc @ W # (228146, 27) @ (27, 27) -> (228146, 27)\n",
    "counts = logits.exp() # (228146, 27)\n",
    "probs = counts / counts.sum(1, keepdims=True) # (228146, 27) / (228146, 1) -> (228146, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4eef01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0047, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0165, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0717, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0127, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0258, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0, 5], probs[1, 13], probs[2, 13], probs[3, 1], probs[4, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa15ea8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0047, 0.0165, 0.0717, 0.0127, 0.0258])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[[0, 1, 2, 3, 4], [5, 13, 13, 1, 0]].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c235efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0047, 0.0165, 0.0717, 0.0127, 0.0258])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[torch.arange(5), ys[:5]].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abbe5457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0225)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-probs[torch.arange(5), ys[:5]].log().mean().data #Vectorized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95ffb007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[torch.arange(num), ys].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "458fe87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6674909591674805\n",
      "3.316964626312256\n",
      "3.112459897994995\n",
      "2.9850077629089355\n",
      "2.8959949016571045\n",
      "2.8305578231811523\n",
      "2.781200647354126\n",
      "2.7433338165283203\n",
      "2.7136714458465576\n",
      "2.6898412704467773\n",
      "2.670196056365967\n",
      "2.653632164001465\n",
      "2.639416456222534\n",
      "2.6270511150360107\n",
      "2.6161880493164062\n",
      "2.6065728664398193\n",
      "2.5980124473571777\n",
      "2.5903570652008057\n",
      "2.5834829807281494\n",
      "2.5772883892059326\n",
      "2.5716865062713623\n",
      "2.5666022300720215\n",
      "2.5619726181030273\n",
      "2.5577425956726074\n",
      "2.5538647174835205\n",
      "2.5502989292144775\n",
      "2.5470094680786133\n",
      "2.543966770172119\n",
      "2.541144371032715\n",
      "2.538520574569702\n",
      "2.5360753536224365\n",
      "2.53379225730896\n",
      "2.53165602684021\n",
      "2.529653787612915\n",
      "2.5277740955352783\n",
      "2.5260064601898193\n",
      "2.5243418216705322\n",
      "2.5227720737457275\n",
      "2.521289348602295\n",
      "2.519888401031494\n",
      "2.518561601638794\n",
      "2.5173046588897705\n",
      "2.5161123275756836\n",
      "2.514979600906372\n",
      "2.513902425765991\n",
      "2.5128777027130127\n",
      "2.51190185546875\n",
      "2.5109713077545166\n",
      "2.5100831985473633\n",
      "2.509235382080078\n",
      "2.5084245204925537\n",
      "2.5076489448547363\n",
      "2.506906747817993\n",
      "2.506195306777954\n",
      "2.5055136680603027\n",
      "2.504859447479248\n",
      "2.5042314529418945\n",
      "2.5036282539367676\n",
      "2.5030484199523926\n",
      "2.5024912357330322\n",
      "2.5019543170928955\n",
      "2.5014376640319824\n",
      "2.5009398460388184\n",
      "2.500459909439087\n",
      "2.49999737739563\n",
      "2.4995503425598145\n",
      "2.499119281768799\n",
      "2.4987030029296875\n",
      "2.498300552368164\n",
      "2.4979114532470703\n",
      "2.497534990310669\n",
      "2.49717116355896\n",
      "2.4968183040618896\n",
      "2.4964771270751953\n",
      "2.4961462020874023\n",
      "2.49582576751709\n",
      "2.4955151081085205\n",
      "2.495213747024536\n",
      "2.4949207305908203\n",
      "2.4946372509002686\n",
      "2.494361400604248\n",
      "2.494093418121338\n",
      "2.4938337802886963\n",
      "2.4935808181762695\n",
      "2.493335247039795\n",
      "2.493095874786377\n",
      "2.492863416671753\n",
      "2.4926373958587646\n",
      "2.492417573928833\n",
      "2.4922032356262207\n",
      "2.4919943809509277\n",
      "2.491791248321533\n",
      "2.4915931224823\n",
      "2.4914002418518066\n",
      "2.4912121295928955\n",
      "2.4910290241241455\n",
      "2.4908502101898193\n",
      "2.490675449371338\n",
      "2.4905054569244385\n",
      "2.4903392791748047\n",
      "loss without regularization: 2.474456548690796\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for _ in range(100):\n",
    "  \n",
    "    # forward pass\n",
    "    logits = xenc @ W # (228146, 27) @ (27, 27) -> (228146, 27)\n",
    "    counts = logits.exp() # (228146, 27)\n",
    "    probs = counts / counts.sum(1, keepdims=True) # (228146, 27) / (228146, 1) -> (228146, 27)\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean() #L2 regularization\n",
    "    print(loss.item())\n",
    "  \n",
    "    # backward pass\n",
    "    W.grad = None # set to zero the gradient\n",
    "    loss.backward()\n",
    "  \n",
    "    # update\n",
    "    W.data += -50 * W.grad\n",
    "print(f'loss without regularization: {-probs[torch.arange(num), ys].log().mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72ec6fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4901773929595947\n",
      "2.490097761154175\n",
      "2.4900197982788086\n",
      "2.4899418354034424\n",
      "2.48986554145813\n",
      "2.4897899627685547\n",
      "2.489715099334717\n",
      "2.4896411895751953\n",
      "2.4895682334899902\n",
      "2.4894959926605225\n",
      "2.489424228668213\n",
      "2.489353656768799\n",
      "2.489284038543701\n",
      "2.489215135574341\n",
      "2.4891467094421387\n",
      "2.489079475402832\n",
      "2.4890124797821045\n",
      "2.4889466762542725\n",
      "2.4888813495635986\n",
      "2.488816738128662\n",
      "2.488753080368042\n",
      "2.48868989944458\n",
      "2.4886276721954346\n",
      "2.488565683364868\n",
      "2.4885048866271973\n",
      "2.4884443283081055\n",
      "2.488384485244751\n",
      "2.488325357437134\n",
      "2.488266944885254\n",
      "2.4882090091705322\n",
      "2.488151788711548\n",
      "2.488095283508301\n",
      "2.488039255142212\n",
      "2.487983465194702\n",
      "2.487928628921509\n",
      "2.4878742694854736\n",
      "2.487820625305176\n",
      "2.487767219543457\n",
      "2.4877147674560547\n",
      "2.4876625537872314\n",
      "2.4876110553741455\n",
      "2.4875600337982178\n",
      "2.487509250640869\n",
      "2.487459182739258\n",
      "2.4874095916748047\n",
      "2.487360715866089\n",
      "2.4873123168945312\n",
      "2.4872639179229736\n",
      "2.4872162342071533\n",
      "2.4871692657470703\n",
      "2.4871222972869873\n",
      "2.4870760440826416\n",
      "2.4870307445526123\n",
      "2.486985206604004\n",
      "2.486940383911133\n",
      "2.48689603805542\n",
      "2.486851930618286\n",
      "2.4868080615997314\n",
      "2.486764907836914\n",
      "2.486722230911255\n",
      "2.486680030822754\n",
      "2.486637830734253\n",
      "2.48659610748291\n",
      "2.4865550994873047\n",
      "2.486514091491699\n",
      "2.486473798751831\n",
      "2.486433982849121\n",
      "2.486394166946411\n",
      "2.4863545894622803\n",
      "2.486315965652466\n",
      "2.4862775802612305\n",
      "2.486239433288574\n",
      "2.486201047897339\n",
      "2.486163377761841\n",
      "2.48612642288208\n",
      "2.4860892295837402\n",
      "2.4860525131225586\n",
      "2.4860167503356934\n",
      "2.48598051071167\n",
      "2.4859447479248047\n",
      "2.4859097003936768\n",
      "2.485874891281128\n",
      "2.485840082168579\n",
      "2.4858057498931885\n",
      "2.485771656036377\n",
      "2.4857378005981445\n",
      "2.4857046604156494\n",
      "2.485671281814575\n",
      "2.485638380050659\n",
      "2.4856057167053223\n",
      "2.4855732917785645\n",
      "2.485541343688965\n",
      "2.4855096340179443\n",
      "2.485477924346924\n",
      "2.4854469299316406\n",
      "2.4854156970977783\n",
      "2.4853851795196533\n",
      "2.4853546619415283\n",
      "2.4853243827819824\n",
      "2.485294818878174\n",
      "loss without regularization: 2.4680967330932617\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for _ in range(100):\n",
    "  \n",
    "    # forward pass\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
    "    print(loss.item())\n",
    "  \n",
    "    # backward pass\n",
    "    W.grad = None # set to zero the gradient\n",
    "    loss.backward()\n",
    "  \n",
    "    # update\n",
    "    W.data += -25 * W.grad\n",
    "print(f'loss without regularization: {-probs[torch.arange(num), ys].log().mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f810ad9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myeazljzorhna\n",
      "s\n",
      "h\n",
      "zknekniiiayid\n",
      "ralra\n",
      "cba\n",
      "alpg\n",
      "dcirtroimniatumzalaenesqmmdyeav\n",
      "snijalegebearktezemhr\n",
      "ros\n",
      "eialm\n",
      "aa\n",
      "dvlsrharsiarlnyaaiaxrtamhrhegemnqnia\n",
      "dym\n",
      "mr\n",
      "jtroadyreagianialoni\n",
      "ds\n",
      "asnyiemulmneemrliear\n",
      "rlaaa\n",
      "a\n",
      "a\n",
      "ayrsw\n",
      "iia\n",
      "htefeo\n",
      "z\n",
      "anyltdnejymzyjr\n",
      "j\n",
      "h\n",
      "km\n",
      "ljgoemriiiiiabatacanaelayddia\n",
      "kiadco\n",
      "a\n",
      "smngiiiiekrha\n",
      "munreblebalcfvebalzemhnetoniiyjednwemyklebiarhmcisfniyad\n",
      "pmk\n",
      "oneoz\n",
      "dxlba\n",
      "ba\n",
      "nonvyahreaj\n",
      "jmvulbania\n"
     ]
    }
   ],
   "source": [
    "for _ in range(40): \n",
    "    out = []\n",
    "    i = 0\n",
    "    \n",
    "    while True:\n",
    "        i = torch.multinomial(probs[i], num_samples=1, replacement=True).item()\n",
    "        out.append(itos[i])\n",
    "        if i == 0:\n",
    "            break\n",
    "            \n",
    "    print(''.join(out)[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb04df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
